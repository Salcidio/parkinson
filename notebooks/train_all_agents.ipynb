{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's Multi-Agent System - Training Notebook\n",
    "\n",
    "This notebook trains all agents in the unified Parkinson's disease multi-agent system.\n",
    "\n",
    "## What This Does:\n",
    "1Ô∏è‚É£ Sets up environment and dependencies\n",
    "2Ô∏è‚É£ Mounts Google Drive for data access\n",
    "3Ô∏è‚É£ Trains Motor, Biomarker, and Non-Motor agents\n",
    "4Ô∏è‚É£ Saves trained models to Google Drive\n",
    "5Ô∏è‚É£ Visualizes training results\n",
    "\n",
    "## Before Running:\n",
    "- Upload PPMI data to `/content/drive/MyDrive/parkinson_data/`\n",
    "- Required files:\n",
    "  - `motor_merged.csv` (motor assessments)\n",
    "  - `datscan.csv` (DaTSCAN imaging)\n",
    "  - `non_motor_merged.csv` (non-motor assessments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"‚úì Running in Google Colab\")\n",
    "    \n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Clone repository (if not already present)\n",
    "    import os\n",
    "    if not os.path.exists('/content/parkinson'):\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/your-repo/parkinson.git /content/parkinson\n",
    "    \n",
    "    # Change to project directory\n",
    "    %cd /content/parkinson\n",
    "else:\n",
    "    print(\"‚úì Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q pandas numpy scikit-learn lightgbm xgboost shap matplotlib seaborn tqdm joblib\n",
    "\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from config import Config\n",
    "from training.pipeline import TrainingPipeline\n",
    "from agents.motor_agent import MotorAgent\n",
    "from agents.biomarker_agent import BiomarkerAgent\n",
    "from agents.non_motor_agent import NonMotorAgent\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úì Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration\n",
    "cfg = Config()\n",
    "cfg.setup()\n",
    "\n",
    "print(f\"Data directory: {cfg.paths.data_dir}\")\n",
    "print(f\"Models directory: {cfg.paths.models_dir}\")\n",
    "print(f\"Environment: {'Google Colab' if cfg.is_colab else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_files = {\n",
    "    'Motor': 'motor_merged.csv',\n",
    "    'DaTSCAN': 'datscan.csv',\n",
    "    'Non-Motor': 'non_motor_merged.csv'\n",
    "}\n",
    "\n",
    "print(\"Checking data files...\\n\")\n",
    "for name, filename in data_files.items():\n",
    "    filepath = cfg.paths.raw_data_dir / filename\n",
    "    exists = filepath.exists()\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"{status} {name}: {filename} {'(found)' if exists else '(NOT FOUND)'}\")\n",
    "\n",
    "print(\"\\nüí° Note: Upload missing files to your Google Drive parkinson_data folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train All Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training pipeline\n",
    "pipeline = TrainingPipeline(config=cfg)\n",
    "\n",
    "# Train all agents\n",
    "agents = pipeline.train_all(\n",
    "    agents_to_train=['motor', 'biomarker', 'non_motor_cognitive'],\n",
    "    model_type='lightgbm'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training metrics\n",
    "results = []\n",
    "for agent_name, result in pipeline.training_results.items():\n",
    "    if 'metrics' in result:\n",
    "        metrics = result['metrics']\n",
    "        results.append({\n",
    "            'Agent': agent_name,\n",
    "            'MAE': metrics.get('mae', 0),\n",
    "            'R¬≤': metrics.get('r2', 0),\n",
    "            'RMSE': metrics.get('rmse', 0)\n",
    "        })\n",
    "\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Plot metrics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # MAE\n",
    "    axes[0].bar(results_df['Agent'], results_df['MAE'], color='steelblue')\n",
    "    axes[0].set_title('Mean Absolute Error (MAE)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('MAE')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # R¬≤\n",
    "    axes[1].bar(results_df['Agent'], results_df['R¬≤'], color='green', alpha=0.7)\n",
    "    axes[1].set_title('R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('R¬≤')\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # RMSE\n",
    "    axes[2].bar(results_df['Agent'], results_df['RMSE'], color='coral')\n",
    "    axes[2].set_title('Root Mean Squared Error (RMSE)', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('RMSE')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTraining Metrics Summary:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No training metrics available (agents may use rule-based assessment)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example patient profiles\n",
    "motor_profile = {'NUPDRS3_BL': 20.0, 'months_since_bl': 0.0}\n",
    "bio_profile = {'putamen_mean_sbr': 1.8, 'striatal_asym': 0.4, 'low_dat_risk': 1}\n",
    "nm_profile = {'updrs_nonmotor_cognitive_BL': 22.0, 'months_since_bl': 0.0}\n",
    "\n",
    "print(\"Making test predictions...\\n\")\n",
    "\n",
    "# Motor agent\n",
    "if 'motor' in agents:\n",
    "    motor_payload = agents['motor'].analyze(patient_profile=motor_profile)\n",
    "    print(f\"Motor Agent: {motor_payload}\")\n",
    "    print(f\"  Narrative: {motor_payload.clinical_narrative}\\n\")\n",
    "\n",
    "# Biomarker agent\n",
    "if 'biomarker' in agents:\n",
    "    bio_payload = agents['biomarker'].analyze(patient_profile=bio_profile)\n",
    "    print(f\"Biomarker Agent: {bio_payload}\")\n",
    "    print(f\"  Narrative: {bio_payload.clinical_narrative}\\n\")\n",
    "\n",
    "# Non-motor agent\n",
    "if 'non_motor_cognitive' in agents:\n",
    "    nm_payload = agents['non_motor_cognitive'].analyze(patient_profile=nm_profile)\n",
    "    print(f\"Non-Motor Agent: {nm_payload}\")\n",
    "    print(f\"  Narrative: {nm_payload.clinical_narrative}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Agent Orchestration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestrator import ClinicalOrchestrator\n",
    "\n",
    "# Create orchestrator\n",
    "orch = ClinicalOrchestrator(config=cfg)\n",
    "\n",
    "# Collect payloads\n",
    "payloads = []\n",
    "if 'motor' in agents:\n",
    "    payloads.append(agents['motor'].analyze(patient_profile=motor_profile))\n",
    "if 'biomarker' in agents:\n",
    "    payloads.append (agents['biomarker'].analyze(patient_profile=bio_profile))\n",
    "if 'non_motor_cognitive' in agents:\n",
    "    payloads.append(agents['non_motor_cognitive'].analyze(patient_profile=nm_profile))\n",
    "\n",
    "# Fuse predictions\n",
    "fusion_result = orch.uncertainty_aware_fusion(payloads)\n",
    "ci = orch.calculate_confidence_interval(payloads)\n",
    "report = orch.generate_report(fusion_result)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-AGENT CLINICAL ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nGlobal Risk Score: {fusion_result['global_risk_score']:.2f} ¬± {ci:.2f}\")\n",
    "print(f\"\\n{report}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Models to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models are automatically saved during training to cfg.paths.models_dir\n",
    "print(f\"Models saved to: {cfg.paths.models_dir}\")\n",
    "\n",
    "# List saved models\n",
    "import os\n",
    "models_path = cfg.paths.models_dir\n",
    "if models_path.exists():\n",
    "    print(\"\\nSaved models:\")\n",
    "    for agent_dir in models_path.iterdir():\n",
    "        if agent_dir.is_dir():\n",
    "            print(f\"   {agent_dir.name}/\")\n",
    "            for file in agent_dir.iterdir():\n",
    "                print(f\"    - {file.name}\")\n",
    "else:\n",
    "    print(\"No models directory found\")\n",
    "\n",
    "print(\"\\n‚úì Training complete! Models saved to Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training Complete!\n",
    "\n",
    "Your trained models are now saved in Google Drive and ready for use.\n",
    "\n",
    "### Next Steps:\n",
    "1.  Run `inference_demo.ipynb` to test predictions\n",
    "2.  Use the trained agents in your research\n",
    "3.  Share models with collaborators via Drive\n",
    "\n",
    "### Notes:\n",
    "- Models are saved in pickle format for easy loading\n",
    "- Metadata includes training metrics and timestamps\n",
    "- SHAP explainers are saved with models for interpretability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
